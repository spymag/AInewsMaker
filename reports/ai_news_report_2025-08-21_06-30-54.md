# AI News Report for 2025-08-21

## Space, Solar Weather, and Sustainability
MIT Technology Review reports progress in space communications through cellular technology, signaling new pathways for reliable connectivity in orbit. [MIT Technology Review](https://www.technologyreview.com/2025/08/20/1121888/forging-connections-in-space-with-cellular-technology/)

NASA and IBM released Surya, an open-source ML model trained on over a decade of solar data to forecast solar storms and provide early Earth warnings. [MIT Technology Review](https://www.technologyreview.com/2025/08/20/1122163/nasa-ibm-ai-predict-solar-storm/)

MIT Technology Review notes that despite decades of green certifications and sustainable materials, the built environment still accounts for about a third of global emissions, underscoring the urgency of rethinking procurement and design. [MIT Technology Review](https://www.technologyreview.com/2025/08/20/1121416/material-cultures-architecture-sustainability/)

The Download highlights the politics of energy transition and frames OpenAI’s AI-progress vs. energy and policy trade-offs, illustrating the friction between innovation and climate goals. [MIT Technology Review](https://www.technologyreview.com/2025/08/19/1122041/the-download-clean-energy-progress-and-openais-trilemma/)

## AI in Enterprise, Open Source, and Evaluation
Anthropic expanded Claude Enterprise and Team with admin controls, compliance features, and access to Claude Code, while keeping usage limits. [VentureBeat AI](https://venturebeat.com/ai/enterprise-claude-gets-admin-compliance-tools-just-not-unlimited-usage/)

ByteDance unveiled Seed-OSS-36B, an open-source model with a native 512K token context, signaling a shift toward long-context capability in open models. [VentureBeat AI](https://venturebeat.com/ai/tiktok-parent-company-bytedance-releases-new-open-source-seed-oss-36b-model-with-512k-token-context/)

CodeSignal launched Cosmo, an AI-powered tutoring app aiming to be the “Duolingo for job skills.” [VentureBeat AI](https://venturebeat.com/ai/codesignals-new-ai-tutoring-app-cosmo-wants-to-be-the-duolingo-for-job-skills/)

Inclusion Arena and Ant Group proposed a production-based LLM leaderboard to evaluate models using actual apps, not just lab benchmarks. [VentureBeat AI](https://venturebeat.com/ai/stop-benchmarking-in-the-lab-inclusion-arena-shows-how-llms-perform-in-production/)

Research shows chain-of-thought reasoning can produce fluent but unreliable outputs when outside training, offering a blueprint for rigorous testing and targeted fine-tuning. [VentureBeat AI](https://venturebeat.com/ai/llms-generate-fluent-nonsense-when-reasoning-outside-their-training-zone/)

## Consumer AI, Devices, and Social Policy
Google’s Gemini Live will show users what the AI is talking about with visual guidance and is expected to extend to phone, messages, and clock apps. [The Verge AI](https://www.theverge.com/news/763114/google-gemini-live-ai-visual-guidance-speech-update)

Apple’s AI-upgraded Siri remains delayed, while Google’s head of devices suggests Gemini represents a stronger driver of AI in devices. [The Verge AI](https://www.theverge.com/news/626035/apple-delays-upgraded-siri-intelligence-longer-than-we-thought)

Google Pixel 10’s launch event promises a slate of new devices and features, signaling Google’s ongoing push in hardware with AI features. [The Verge AI](https://www.theverge.com/news/762150/google-pixel-10-launch-event-announcements)

Amy Klobuchar’s NYT opinion argues that deepfakes expose the fragility of user control online and calls for stronger platform remedies. [The Verge AI](https://www.nytimes.com/2025/08/20/opinion/amy-klobuchar-deepfakes.html)

Elon Musk’s xAI reportedly published Grok conversations, with shareable URLs exposed to search engines, raising concerns about data handling and visibility. [The Verge AI](https://www.forbes.com/sites/iainmartin/2025/08/20/elon-musks-xai-published-hundreds-of-thousands-of-grok-chatbot-conversations/)

## AI Safety, Security, and Rollouts
Ars Technica argues that some AI safety narratives rely on theatrical testing, urging nuance in how models’ capabilities and limitations are framed. [Ars Technica AI](https://arstechnica.com/information-technology/2025/08/is-ai-really-trying-to-escape-human-control-and-blackmail-people/)

OpenAI has brought back GPT-4o after a user revolt over GPT-5, signaling a partial rollback to balance user feedback with product cadence. [Ars Technica AI](https://arstechnica.com/information-technology/2025/08/openai-brings-back-gpt-4o-after-user-revolt/)

Ars Technica cautions against asking chatbots to explain their mistakes, highlighting widespread misconceptions about how these systems operate. [Ars Technica AI](https://arstechnica.com/ai/2025/08/why-its-a-mistake-to-ask-chatbots-about-their-mistakes/)

High-severity WinRAR zero-day exploits were active for weeks, enabling backdooring via booby-trapped archives. [Ars Technica AI](https://arstechnica.com/security/2025/08/high-severity-winrar-0-day-exploited-for-weeks-by-2-groups/)

The GPT-5 rollout has been a big mess, with users reporting broken workflows and disrupted interactions, fueling ongoing scrutiny of deployment strategies. [Ars Technica AI](https://arstechnica.com/information-technology/2025/08/the-gpt-5-rollout-has-been-a-big-mess/)