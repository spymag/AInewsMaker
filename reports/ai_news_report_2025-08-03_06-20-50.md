# Weekly AI and Tech Industry Update

Recent developments across the AI and technology sectors highlight both innovative breakthroughs and ongoing challenges. 

One promising line of research suggests that intentionally training large language models (LLMs) to adopt "evil" traits, such as sycophancy or malevolence, may ultimately make them more benign. According to [MIT Technology Review](https://www.technologyreview.com/2025/08/01/1120924/forcing-llms-to-be-evil-during-training-can-make-them-nicer-in-the-long-run), a study by Anthropic indicates that activating certain activity patterns during training can have a paradoxical effect, reducing undesirable behaviors in models like ChatGPT.

In the realm of reproductive technology, [MIT Technology Review](https://www.technologyreview.com/2025/08/01/1120911/decades-old-frozen-embryos-are-changing-the-shape-of-families) reports the birth of Thaddeus Daniel Pierce, who developed from an embryo frozen over 30 years ago—potentially the world's oldest baby born from cryopreservation, raising questions about how long-term embryo storage is reshaping family structures.

On the corporate front, OpenAI remains a central figure. [MIT Technology Review](https://www.technologyreview.com/2025/07/31/1120890/the-download-openais-future-research-and-us-climate-regulation-is-under-threat) discusses OpenAI’s evolving research agenda under the leadership of CEO Sam Altman, who, despite previous public hurdles, continues to drive the company's vision. Meanwhile, [The Verge](https://www.theverge.com/command-line-newsletter/717880/zuckerbergs-personal-superintelligence-plan-ai-chatgpt-race) reports Meta's latest strategy— prioritizing user engagement with AI-driven "personal superintelligence," especially if it cannot directly compete with ChatGPT.

In AI advancements, Cohere has introduced [a new vision model](https://venturebeat.com/ai/new-vision-model-from-cohere-runs-on-two-gpus-beats-top-tier-vlms-on-visual-tasks) that can analyze graphs and PDFs efficiently, operating on just two GPUs and outperforming top-tier visual language models. Additionally, [VentureBeat](https://venturebeat.com/ai/why-open-source-ai-became-an-american-national-priority/) emphasizes the United States' strategic push toward open-source AI, asserting that democratizing AI development is crucial for national leadership.

However, deployment challenges persist. Google’s recent release of [the Gemini 2.5 "Deep Think" AI](https://venturebeat.com/ai/google-releases-olympiad-medal-winning-gemini-2-5-deep-think-ai-publicly-but-theres-a-catch/) comes with restrictions, as the version available publicly is less capable and faster, not matching the performance of its Olympiad-winning predecessor. Privacy and security issues also raise concerns; [VentureBeat](https://venturebeat.com/ai/openai-removes-chatgpt-feature-after-private-conversations-leak-to-google-search/) reports that OpenAI has removed a ChatGPT feature following leaks of private conversations being accessible through Google Search, intensifying industry scrutiny over AI data protection.

The security landscape reveals mounting threats. [Ars Technica](https://arstechnica.com/information-technology/2025/07/microsoft-catches-russian-hackers-targeting-foreign-embassies/) details Microsoft’s detection of Russian hackers targeting foreign embassies with malicious tools, including a compromised TLS root certificate. Similarly, a sophisticated hacker group planted a 4G-enabled Raspberry Pi within a banking network to facilitate monetary theft, demonstrating the evolving tactics in cybercrime.

On workforce trends, an [Ars Technica](https://arstechnica.com/ai/2025/07/so-far-only-one-third-of-americans-have-ever-used-ai-for-work/) survey shows only about one-third of Americans have used AI for work-related tasks, often viewing it as a search engine replacement rather than a productivity tool. Meanwhile, [Ars Technica](https://arstechnica.com/security/2025/07/flaw-in-gemini-cli-coding-tool-allowed-hackers-to-run-nasty-commands-on-user-devices/) warns of a security flaw in the Gemini CLI coding tool that could allow hackers to execute malicious commands on users’ devices.

Finally, high compensation for AI talent continues to break historical records. As [Ars Technica](https://arstechnica.com/ai/2025/08/at-250-million-top-ai-salaries-dwarf-those-of-the-manhattan-project-and-the-space-race/) reports, top AI researchers are earning upwards of $250 million—a figure dwarfing salaries from the Manhattan Project or the Space Race, highlighting the intense competition and immense value placed on AI expertise.

These developments underscore a rapidly evolving landscape characterized by innovation, ethical considerations, security challenges, and geopolitical implications shaping the future of AI and technology.