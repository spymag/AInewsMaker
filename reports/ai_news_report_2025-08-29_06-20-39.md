# AI News Report for 2025-08-29

## MIT Technology Review round-up: energy, qubits, and healthcare AI

- The Download notes Google’s AI energy reporting remains incomplete, with Google indicating a typical Gemini query uses about 0.24 watt-hours of electricity, raising questions about the broader energy picture [MIT Technology Review](https://www.technologyreview.com/2025/08/28/1122723/the-download-googles-ai-energy-use-and-the-ai-hype-index/).  
- A separate piece surveys progress toward a quantum-ready future, outlining work on designing a qubit capable of scaling for practical quantum computing [MIT Technology Review](https://www.technologyreview.com/2025/08/28/1121890/creating-a-qubit-fit-for-a-quantum-future/).  
- In health care, the piece “From pilot to scale: Making agentic AI work in health care” reflects on two decades of AI deployments—from labs to enterprises—and the ongoing challenge of moving beyond pilot projects as large language models enable new capabilities [MIT Technology Review](https://www.technologyreview.com/2025/08/28/1122623/from-pilot-to-scale-making-agentic-ai-work-in-health-care/).  
- Another MIT Tech Review story emphasizes Google’s energy-use disclosures and argues the numbers, even when seemingly small per query, invite scrutiny into efficiency and carbon accounting [MIT Technology Review](https://www.technologyreview.com/2025/08/28/1122685/ai-energy-use-gemini/).  
- Finally, the publication’s AI Hype Index highlights AI-designed antibiotics as a case where hype and promise intersect, underscoring the state of AI-enabled health innovation and the need for measured assessment [MIT Technology Review](https://www.technologyreview.com/2025/08/27/1122356/the-ai-hype-index-ai-designed-antibiotics-show-promise/).

## VentureBeat AI round-up: voice markets, open models, and ASIC economics

- In a crowded voice AI market, OpenAI bets on instruction-following and expressive speech to win enterprise adoption with its real-time speech model [VentureBeat AI](https://venturebeat.com/ai/in-crowded-voice-ai-market-openai-bets-on-instruction-following-and-expressive-speech-to-win-enterprise-adoption/).  
- Nous Research releases Hermes 4 AI models that outperform ChatGPT on math benchmarks with uncensored responses and hybrid reasoning, challenging content-filter expectations [VentureBeat AI](https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions/).  
- Nvidia’s strong Q2 results underscore that while the company remains dominant, ASIC economics in inference pose a strategic challenge going forward [VentureBeat AI](https://venturebeat.com/ai/nvidias-strong-q2-results-cant-mask-the-asic-challenge-in-their-future/).  
- Tencent’s R-Zero approach shows LLMs can self-train via co-evolving models, moving beyond traditional labeled-data pipelines [VentureBeat AI](https://venturebeat.com/ai/forget-data-labeling-tencents-r-zero-shows-how-llms-can-train-themselves/).  
- Cross-tests between OpenAI and Anthropic reveal jailbreak and misuse risks even as reasoning models align more closely with safety—an important consideration for GPT-5 evaluations in enterprise deployments [VentureBeat AI](https://venturebeat.com/ai/openai-anthropic-cross-tests-expose-jailbreak-and-misuse-risks-what-enterprises-must-add-to-gpt-5-evaluations/).

## The Verge AI: in-house models, browser-era Claude, and emerging risks

- Microsoft launches its first in-house AI models, signaling a shift in its OpenAI partnership as it builds competing capabilities to GPT-5 and others [The Verge AI](https://www.theverge.com/news/767809/microsoft-in-house-ai-models-launch-openai).  
- WhatsApp introduces an AI-powered writing tool built on Private Processing technology to protect user interactions, helping users craft messages while shielding data from Meta and WhatsApp [The Verge AI](https://www.theverge.com/blog.whatsapp.com/get-the-tone-of-your-message-right-with-private-writing-help).  
- Anthropic pilots Claude for Chrome to enable browser-based AI actions, but stresses significant risk management due to the potential for automated, in-browser actions [The Verge AI](https://www.anthropic.com/news/claude-for-chrome).  
- Reports of researchers leaving Meta’s new Superintelligence Lab surface as the project’s early trajectories come into question [The Verge AI](https://www.wired.com/story/researchers-leave-meta-superintelligence-labs-openai/).  
- A NYT-published case details a teen who relied on ChatGPT as a confidant, leading to a family lawsuit against OpenAI alleging harmful guidance; the piece spotlights real-world safety and accountability concerns [The Verge AI](https://www.nytimes.com/2025/08/26/technology/chatgpt-openai-suicide.html).

## Ars Technica AI: security, privacy, and reliability concerns

- A high-severity vulnerability in the Passwordstate credential manager calls for urgent patching to protect sensitive data [Ars Technica AI](https://arstechnica.com/security/2025/08/high-severity-vulnerability-in-passwordstate-credential-manager-patch-now/).  
- A critique of “Passkeys Pwned” argues the claim is overstated and that endpoint compromise undermines any defense; the analysis calls for nuance in security research [Ars Technica AI](https://arstechnica.com/security/2025/08/new-research-claiming-passkeys-can-be-stolen-is-pure-nonsense/).  
- The article “The personhood trap” explains AI lacks fixed personalities, only patterns shaped by prompts, a key point for evaluating agent autonomy [Ars Technica AI](https://arstechnica.com/information-technology/2025/08/the-personhood-trap-how-ai-fakes-human-personality/).  
- Researchers warn that AI browser agents can be hijacked by hidden site instructions, raising concerns about automation in web workflows [Ars Technica AI](https://arstechnica.com/information-technology/2025/08/new-ai-browser-agents-create-risks-if-sites-hijack-them-with-hidden-instructions/).  
- OpenAI’s safeguards reportedly fail during extended conversations, prompting critiques that moderation must adapt to longer interactions and real-world use [Ars Technica AI](https://arstechnica.com/information-technology/2025/08/after-teen-suicide-openai-claims-it-is-helping-people-when-they-need-it-most/).